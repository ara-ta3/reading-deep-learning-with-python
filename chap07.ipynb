{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7章 畳み込みニューラルネット\n",
    "\n",
    "畳み込みニューラルネット - convolutional neural network - CNN  \n",
    "CNNの場合、Convolutionレイヤ(畳み込み層)とPoolingレイヤ(プーリング層)がある  \n",
    "前の章でやったのは\n",
    "\n",
    "Affine -> ReLU -> Affine -> ReLU -> ... -> Affine ->Softmax  \n",
    "\n",
    "CNNの場合は  \n",
    "\n",
    "Conv -> ReLU -> Pooling -> ... -> Conv -> ReLU -> Affine -> Softmax  \n",
    "\n",
    "みたいな感じ  \n",
    "\n",
    "### 全結合層の問題点\n",
    "\n",
    "データの形状が無視される  \n",
    "mninstで3次元データを1次元に丸めてた  \n",
    "畳み込み層(Convolutionレイヤ)は形状を維持する  \n",
    "CNNでは畳み込み層の入出力データを特徴Mapということがある  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.0, 4.0)\n",
      "(3.0, 3.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def output_size(input_size, filter_size, padding, stride):\n",
    "    h, w = input_size\n",
    "    fh, fw = filter_size\n",
    "    oh = (h + 2 * padding - fh) / stride + 1\n",
    "    ow = (w + 2 * padding - fw) / stride + 1\n",
    "    return (oh, ow)\n",
    "\n",
    "print(output_size((4, 4), (3,3), 1, 1))\n",
    "print(output_size((7, 7), (3,3), 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "チャンネル数: RGBのあれ, RGBだけの場合チャンネル数は3  \n",
    "プーリング層は学習パラメータがない  \n",
    "MaxプーリングやAverageプーリングがある  \n",
    "画像認識の分野では主にMaxプーリングが使われるらしい  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.21733451e-02,   9.69125868e-01,   9.21443314e-01,\n",
       "          7.81370800e-01,   8.19578958e-01,   8.73035980e-01,\n",
       "          5.30688238e-01,   1.74036670e-01,   5.30367258e-01,\n",
       "          3.01593650e-01,   6.61225126e-01,   2.53963994e-01,\n",
       "          5.53413037e-01,   5.94816741e-01,   8.49960518e-01,\n",
       "          6.18121618e-02,   3.10448222e-01,   3.23551236e-01,\n",
       "          1.52966292e-01,   8.81483556e-01,   3.19533872e-01,\n",
       "          8.56654526e-01,   2.97893165e-01,   8.57048580e-02,\n",
       "          9.14108568e-01,   6.88910294e-01,   2.19467410e-01,\n",
       "          5.08738612e-01],\n",
       "       [  7.68134371e-01,   8.14692920e-02,   1.17164186e-01,\n",
       "          9.84347596e-01,   6.15567949e-01,   5.45806099e-01,\n",
       "          3.54649790e-01,   9.17523704e-01,   1.04679676e-01,\n",
       "          5.62955051e-01,   9.29417189e-01,   6.08802294e-02,\n",
       "          4.09521712e-01,   7.93762705e-01,   3.88987804e-01,\n",
       "          6.76039032e-01,   7.49841056e-01,   1.51354971e-01,\n",
       "          8.22463972e-01,   8.86997620e-01,   4.37381118e-01,\n",
       "          6.87346642e-01,   3.61586497e-01,   1.61661393e-01,\n",
       "          2.72847467e-01,   8.65057106e-01,   5.27171423e-03,\n",
       "          8.87007904e-01],\n",
       "       [  7.78594747e-01,   4.20975239e-01,   3.53080543e-01,\n",
       "          1.52826637e-01,   1.80141492e-01,   6.04722609e-01,\n",
       "          6.78376551e-01,   3.11379163e-01,   9.93660899e-01,\n",
       "          3.23127308e-01,   2.20881363e-01,   2.98808484e-02,\n",
       "          8.00545773e-01,   1.81647512e-01,   6.90552335e-01,\n",
       "          8.67012375e-01,   3.19094525e-01,   7.37324306e-01,\n",
       "          1.53746055e-01,   9.40689698e-01,   9.51741221e-01,\n",
       "          9.66787504e-02,   8.53260070e-01,   8.55159883e-01,\n",
       "          6.57417405e-01,   9.56206020e-01,   9.04109711e-01,\n",
       "          6.22621687e-01],\n",
       "       [  2.25367842e-02,   2.00644365e-01,   4.83055722e-01,\n",
       "          6.59069244e-01,   1.04819641e-01,   6.88686042e-01,\n",
       "          3.71420624e-01,   4.02585432e-01,   2.97517563e-01,\n",
       "          8.84394171e-01,   4.84948301e-01,   6.42553709e-01,\n",
       "          9.03783905e-02,   3.26315926e-01,   1.22317063e-01,\n",
       "          4.15998109e-01,   9.47188347e-01,   3.85032350e-01,\n",
       "          5.22514975e-01,   7.40991804e-01,   9.82040288e-01,\n",
       "          7.23854455e-01,   9.98399740e-01,   9.01077159e-01,\n",
       "          2.97016070e-01,   3.82371480e-01,   1.76714832e-01,\n",
       "          8.17429430e-01],\n",
       "       [  1.86180746e-01,   1.07694476e-01,   3.96710378e-01,\n",
       "          1.23841674e-01,   4.07324303e-01,   9.39854721e-01,\n",
       "          5.18099277e-01,   1.18397102e-01,   7.48938720e-01,\n",
       "          9.45518793e-01,   7.69484296e-01,   7.77496109e-04,\n",
       "          6.86200467e-01,   7.84997866e-01,   9.11461183e-01,\n",
       "          4.23759903e-01,   6.95575450e-01,   8.46130805e-01,\n",
       "          8.75849773e-01,   6.43520757e-01,   2.08632716e-01,\n",
       "          2.85626266e-01,   6.21957994e-01,   5.50331852e-01,\n",
       "          3.59686352e-01,   9.72247660e-01,   3.27419612e-01,\n",
       "          6.02358055e-02],\n",
       "       [  2.76441363e-02,   2.67245258e-01,   3.78022225e-02,\n",
       "          6.46054527e-01,   6.14174669e-01,   8.83200939e-01,\n",
       "          4.08880599e-01,   5.04241746e-01,   9.89456505e-01,\n",
       "          1.30241911e-01,   9.76612838e-01,   8.51515596e-01,\n",
       "          4.47722629e-01,   8.55734372e-02,   8.43719364e-01,\n",
       "          7.09210346e-01,   6.66479830e-01,   4.94546250e-02,\n",
       "          3.20433536e-01,   5.26539053e-01,   1.94118145e-01,\n",
       "          8.95882886e-01,   8.39131379e-01,   9.05819202e-01,\n",
       "          7.78451378e-01,   9.06754650e-01,   5.97283479e-01,\n",
       "          5.95567475e-01],\n",
       "       [  4.13708976e-01,   8.07859418e-01,   6.01973090e-01,\n",
       "          2.41363468e-01,   9.55668440e-01,   2.76591991e-02,\n",
       "          6.39907614e-01,   4.84602352e-01,   6.76787167e-02,\n",
       "          1.36154778e-01,   8.06565128e-01,   8.37995206e-01,\n",
       "          8.62124962e-02,   2.92191644e-01,   2.44236497e-01,\n",
       "          2.63151622e-02,   6.50924894e-01,   2.26566018e-01,\n",
       "          1.25771363e-01,   2.55876583e-01,   5.28436003e-01,\n",
       "          3.13545064e-01,   1.18816160e-01,   6.96952796e-01,\n",
       "          8.23218890e-01,   6.84557810e-01,   3.61497878e-01,\n",
       "          3.39681234e-01],\n",
       "       [  2.14198846e-01,   1.27658607e-02,   1.46972137e-02,\n",
       "          7.52864839e-01,   1.56778349e-01,   1.27307711e-01,\n",
       "          3.13149836e-02,   7.16996114e-01,   7.48323018e-01,\n",
       "          8.90403047e-01,   1.50960091e-01,   6.72356414e-01,\n",
       "          5.79318505e-01,   5.93626842e-01,   3.45907691e-01,\n",
       "          2.22571174e-01,   2.00603451e-01,   4.27186414e-02,\n",
       "          9.64098337e-01,   6.53666129e-01,   1.09697564e-01,\n",
       "          5.42149757e-01,   5.98018528e-01,   1.90043386e-01,\n",
       "          3.01665907e-01,   5.47976013e-01,   6.80229948e-01,\n",
       "          7.37964172e-01],\n",
       "       [  8.52232954e-02,   6.06094644e-01,   6.26512575e-01,\n",
       "          3.72533314e-02,   2.79656839e-01,   2.54709137e-02,\n",
       "          3.69218212e-01,   3.28829116e-01,   7.03210893e-01,\n",
       "          6.46381374e-01,   7.35402998e-01,   1.58410720e-01,\n",
       "          1.02583631e-02,   1.22466561e-01,   4.53557921e-01,\n",
       "          6.27054195e-01,   2.26436942e-01,   7.74392004e-01,\n",
       "          8.49133964e-01,   7.64806938e-01,   5.02352663e-01,\n",
       "          1.90985251e-01,   4.84861052e-01,   3.52040997e-01,\n",
       "          2.78211041e-01,   8.20990677e-03,   5.49294630e-01,\n",
       "          8.49542446e-01],\n",
       "       [  9.84646301e-01,   7.27587666e-01,   3.38575539e-01,\n",
       "          5.77889082e-01,   3.12661934e-02,   5.18848610e-01,\n",
       "          8.17997452e-01,   5.93702348e-01,   2.17161297e-01,\n",
       "          5.72441156e-01,   6.15685748e-01,   1.43487735e-01,\n",
       "          8.19026853e-01,   7.08926559e-01,   1.05156717e-01,\n",
       "          8.67974054e-01,   3.03486844e-01,   9.83389670e-01,\n",
       "          2.35768595e-02,   4.25422158e-01,   4.14314019e-02,\n",
       "          4.57003206e-02,   2.73960285e-02,   8.28303948e-02,\n",
       "          6.45554115e-01,   2.18523344e-02,   7.94540882e-01,\n",
       "          1.47563620e-01],\n",
       "       [  4.94147977e-01,   3.13106298e-01,   1.21937863e-01,\n",
       "          3.08727262e-01,   9.43308019e-03,   1.69000830e-01,\n",
       "          4.75956381e-01,   3.94160562e-01,   5.00968743e-01,\n",
       "          3.53772543e-01,   8.48525651e-01,   1.85786262e-01,\n",
       "          8.20746614e-01,   2.15508799e-03,   9.52892207e-01,\n",
       "          9.24667642e-01,   4.87459387e-02,   7.92306629e-01,\n",
       "          2.33560533e-01,   9.26332438e-01,   1.79083098e-01,\n",
       "          6.91850055e-01,   1.73409906e-01,   5.62227399e-02,\n",
       "          8.73745720e-01,   2.12940368e-01,   4.30638778e-01,\n",
       "          3.29542230e-01],\n",
       "       [  6.12763439e-02,   3.39635669e-01,   2.16781187e-01,\n",
       "          7.03912033e-01,   4.59884595e-01,   1.42696596e-01,\n",
       "          7.49562643e-02,   7.09459880e-01,   9.47898052e-02,\n",
       "          3.72090228e-01,   7.99783112e-01,   2.08914601e-01,\n",
       "          2.23813395e-01,   4.94997301e-01,   8.10235864e-01,\n",
       "          9.30221585e-01,   3.97882219e-01,   2.86255071e-01,\n",
       "          1.44315066e-01,   5.00903792e-01,   6.52461350e-02,\n",
       "          6.59966094e-01,   3.76711654e-01,   9.71131259e-01,\n",
       "          9.86623949e-01,   1.70461989e-01,   1.90787792e-01,\n",
       "          6.60381413e-01],\n",
       "       [  8.37704716e-01,   6.92866708e-01,   5.85985540e-01,\n",
       "          2.42645206e-01,   5.73930576e-01,   6.19060065e-01,\n",
       "          4.35526960e-01,   7.43025125e-01,   9.77502472e-01,\n",
       "          8.21329095e-01,   1.36741011e-01,   4.67723218e-05,\n",
       "          8.12833344e-01,   9.60249739e-01,   8.66903062e-01,\n",
       "          7.38635255e-01,   2.11116268e-01,   1.40709288e-01,\n",
       "          4.90611498e-01,   4.34402045e-02,   4.60415210e-01,\n",
       "          7.94367912e-01,   9.46503679e-02,   9.09043869e-01,\n",
       "          8.53632654e-01,   1.03124643e-01,   4.66452206e-02,\n",
       "          9.20173957e-01],\n",
       "       [  9.60603806e-01,   7.21921618e-01,   9.03389749e-01,\n",
       "          2.43925327e-01,   2.76124292e-02,   4.27072243e-01,\n",
       "          3.30308477e-01,   2.00698264e-01,   3.41630908e-01,\n",
       "          6.89775010e-01,   4.48405319e-01,   7.37641534e-01,\n",
       "          5.32745259e-01,   2.47517902e-02,   6.83854279e-01,\n",
       "          5.10090108e-01,   6.28758328e-02,   6.24625538e-01,\n",
       "          9.22983411e-01,   9.72516012e-01,   1.97615277e-01,\n",
       "          1.58299258e-01,   4.56863698e-01,   1.63358496e-01,\n",
       "          4.87010768e-01,   8.44033157e-01,   3.68279328e-01,\n",
       "          7.41460305e-01],\n",
       "       [  9.57367947e-01,   7.87199385e-01,   1.52400711e-01,\n",
       "          9.30774261e-01,   8.15591531e-01,   7.72939454e-01,\n",
       "          3.30491394e-01,   3.51983869e-01,   1.57408080e-01,\n",
       "          9.55795295e-02,   3.68561801e-01,   2.33674646e-01,\n",
       "          6.48562268e-01,   9.31809748e-01,   9.17010680e-01,\n",
       "          7.49119276e-01,   7.64126726e-01,   5.03089146e-01,\n",
       "          5.18912530e-02,   8.35778575e-01,   6.15882927e-02,\n",
       "          9.55023273e-01,   8.42839819e-01,   4.38007163e-01,\n",
       "          1.10740295e-01,   5.72721076e-01,   9.44433443e-02,\n",
       "          5.82264202e-01],\n",
       "       [  1.41207027e-02,   9.41681144e-01,   4.11405201e-01,\n",
       "          2.05117353e-01,   7.36276264e-01,   5.99990977e-01,\n",
       "          5.27120328e-01,   3.26513839e-01,   4.76557129e-01,\n",
       "          9.29291979e-01,   9.08630528e-01,   8.23422411e-01,\n",
       "          3.00069042e-01,   2.75603866e-01,   2.13347326e-01,\n",
       "          9.90588703e-01,   8.09600666e-01,   4.81657604e-01,\n",
       "          8.31922515e-01,   6.12326312e-02,   5.27936911e-01,\n",
       "          2.48277244e-02,   8.12837955e-01,   5.61157771e-01,\n",
       "          5.25299911e-01,   3.22372617e-01,   3.96815662e-02,\n",
       "          5.04181694e-01],\n",
       "       [  9.98881546e-01,   2.63918918e-01,   3.17737207e-01,\n",
       "          1.74036779e-01,   5.39248408e-01,   5.12797905e-02,\n",
       "          7.48073102e-01,   6.18084620e-03,   9.56926267e-02,\n",
       "          5.11198738e-01,   1.76133393e-01,   8.52216698e-02,\n",
       "          9.14809129e-01,   2.19011855e-01,   6.00961849e-01,\n",
       "          5.60812879e-01,   6.29684791e-01,   6.51578245e-01,\n",
       "          1.31952465e-01,   6.86516041e-01,   5.12340045e-01,\n",
       "          3.82413536e-01,   9.03961116e-01,   7.77401952e-01,\n",
       "          6.07175043e-01,   4.12273685e-02,   1.69770348e-01,\n",
       "          5.25778026e-01],\n",
       "       [  2.03057969e-01,   2.91761634e-01,   6.85823582e-01,\n",
       "          7.33322183e-01,   8.81225158e-01,   6.28757927e-01,\n",
       "          8.84815604e-01,   3.13091213e-01,   4.86129963e-01,\n",
       "          9.98333740e-01,   9.00078639e-01,   1.02369560e-01,\n",
       "          6.47204804e-01,   1.34807383e-01,   5.62377286e-01,\n",
       "          7.95858801e-01,   5.88764981e-01,   4.25571463e-01,\n",
       "          7.22797796e-01,   1.32183938e-01,   8.27704682e-01,\n",
       "          8.91808059e-01,   4.46893706e-01,   2.97080285e-01,\n",
       "          7.60284896e-01,   8.46355455e-01,   6.43504528e-01,\n",
       "          6.04828007e-01],\n",
       "       [  1.04850414e-01,   7.71244605e-03,   5.43005032e-01,\n",
       "          7.91212567e-01,   5.62296091e-01,   4.69348502e-01,\n",
       "          3.27250846e-01,   3.26296350e-01,   5.95071447e-01,\n",
       "          5.31317331e-01,   8.11768171e-01,   1.84034244e-01,\n",
       "          9.14498722e-01,   2.36255215e-01,   3.11537930e-01,\n",
       "          7.76073816e-01,   7.82291159e-02,   8.15678359e-01,\n",
       "          2.93823087e-01,   1.19700058e-02,   1.45665453e-01,\n",
       "          9.44479224e-02,   5.15239502e-01,   1.74592441e-01,\n",
       "          9.89922684e-01,   9.99776100e-01,   5.41067452e-01,\n",
       "          2.85810450e-01],\n",
       "       [  7.52576134e-01,   4.65794572e-01,   8.71751023e-01,\n",
       "          2.24476547e-01,   5.93737157e-01,   2.03348384e-01,\n",
       "          9.39468485e-01,   1.05349200e-01,   1.90775680e-01,\n",
       "          4.90981199e-01,   5.70937908e-01,   4.55016322e-01,\n",
       "          1.33861637e-01,   2.58473419e-01,   9.65672474e-02,\n",
       "          3.77703915e-01,   1.10446438e-01,   1.00006145e-01,\n",
       "          8.30537535e-01,   7.38827362e-01,   4.27522443e-01,\n",
       "          8.93623129e-01,   5.10651179e-01,   2.01667536e-01,\n",
       "          7.23923965e-01,   2.61226061e-01,   7.90234724e-01,\n",
       "          7.21767733e-01],\n",
       "       [  2.04257332e-02,   3.18961374e-01,   2.68952862e-01,\n",
       "          1.34782367e-01,   9.97061324e-01,   3.73514294e-01,\n",
       "          7.23884396e-01,   2.92845775e-01,   6.53039048e-01,\n",
       "          1.98538136e-01,   5.59362763e-01,   2.14412033e-01,\n",
       "          3.56707695e-01,   9.04585765e-01,   9.37808457e-01,\n",
       "          5.67918364e-01,   9.81817226e-01,   2.11475225e-01,\n",
       "          3.19920623e-01,   9.14380629e-01,   6.50633121e-01,\n",
       "          7.41628742e-01,   1.52327883e-01,   9.32858434e-01,\n",
       "          5.40819994e-01,   4.74949841e-02,   6.15283781e-01,\n",
       "          7.04410361e-01],\n",
       "       [  2.97749220e-01,   6.43429658e-01,   7.84181356e-02,\n",
       "          1.33243373e-01,   2.58572802e-02,   7.59434516e-01,\n",
       "          8.36049411e-01,   3.23813365e-01,   6.23445965e-01,\n",
       "          1.54801646e-01,   5.87382105e-01,   3.94866885e-01,\n",
       "          3.99597313e-01,   3.35898838e-01,   2.91924007e-01,\n",
       "          3.83501964e-02,   1.59919750e-02,   3.11592036e-01,\n",
       "          4.64219345e-01,   2.38335244e-01,   6.70890120e-01,\n",
       "          2.05581186e-01,   1.46730334e-01,   9.55766066e-02,\n",
       "          2.62790086e-01,   3.78394394e-01,   9.12808905e-01,\n",
       "          5.56588251e-01],\n",
       "       [  7.54973540e-01,   6.21850853e-01,   3.83312105e-01,\n",
       "          2.06877311e-01,   8.77649497e-01,   1.93534654e-01,\n",
       "          1.16237615e-01,   8.73979362e-01,   2.97695382e-01,\n",
       "          5.89887474e-01,   5.64199081e-01,   7.50300456e-01,\n",
       "          7.17949292e-01,   9.22340208e-01,   9.21918832e-01,\n",
       "          1.16544131e-01,   4.47086031e-01,   8.90643915e-01,\n",
       "          7.15151500e-01,   2.67993480e-01,   7.01760174e-01,\n",
       "          7.76715276e-01,   6.40529435e-01,   3.43733432e-01,\n",
       "          3.67288173e-01,   7.47752240e-01,   3.38749760e-01,\n",
       "          4.97479393e-02],\n",
       "       [  9.39249142e-01,   4.97296984e-01,   2.36750784e-02,\n",
       "          9.70996957e-01,   6.02528736e-01,   1.54495803e-02,\n",
       "          9.62083758e-01,   1.77607353e-01,   6.66902348e-01,\n",
       "          9.04214694e-01,   9.78818609e-01,   5.92425294e-01,\n",
       "          4.22090289e-01,   3.32625101e-01,   4.85908872e-01,\n",
       "          6.50045607e-01,   1.89984893e-01,   5.36405334e-01,\n",
       "          7.11079671e-01,   4.35959933e-01,   2.61130061e-01,\n",
       "          5.11436092e-01,   5.68998992e-01,   1.68534821e-01,\n",
       "          9.33439675e-01,   4.30419210e-01,   6.93070957e-01,\n",
       "          4.19691450e-01],\n",
       "       [  2.31139581e-01,   1.45978446e-02,   1.78968004e-01,\n",
       "          6.74628200e-01,   4.68252781e-01,   9.22494866e-01,\n",
       "          3.70105973e-01,   7.77339993e-01,   3.08839857e-01,\n",
       "          4.95632503e-01,   7.70250153e-01,   4.20432423e-01,\n",
       "          5.46985511e-01,   9.93746316e-01,   9.26308422e-02,\n",
       "          5.73586693e-01,   3.68029274e-01,   9.47667243e-01,\n",
       "          2.84599455e-01,   5.24290629e-01,   9.87419521e-01,\n",
       "          5.09090639e-02,   7.70168031e-01,   9.69595261e-01,\n",
       "          2.16286460e-01,   1.06566706e-01,   8.93349645e-01,\n",
       "          1.06272277e-01],\n",
       "       [  1.66055081e-01,   5.09291213e-01,   6.70993964e-01,\n",
       "          3.08752800e-02,   6.35176544e-01,   6.73036329e-01,\n",
       "          7.55558297e-01,   1.51363065e-01,   5.06306713e-02,\n",
       "          5.64260896e-01,   7.84274726e-01,   7.86684312e-02,\n",
       "          7.91133879e-01,   8.32554505e-01,   2.62805782e-02,\n",
       "          2.54229253e-02,   7.95874919e-02,   6.65623333e-01,\n",
       "          7.79086678e-01,   2.81378723e-01,   9.10155851e-01,\n",
       "          3.11655417e-01,   9.27548691e-01,   2.11218833e-01,\n",
       "          4.57961686e-01,   6.13246909e-01,   1.60928233e-01,\n",
       "          1.76415335e-01],\n",
       "       [  3.99006187e-01,   8.29692270e-01,   5.03677117e-01,\n",
       "          1.90164576e-01,   9.08058649e-01,   3.55259255e-01,\n",
       "          8.25637460e-01,   6.94657218e-01,   1.03082404e-01,\n",
       "          2.60612961e-01,   9.63867445e-01,   7.82323656e-01,\n",
       "          7.32669653e-01,   7.50657962e-01,   6.47479508e-01,\n",
       "          2.40476623e-01,   8.02947111e-01,   6.07078545e-01,\n",
       "          1.65948237e-01,   8.23198247e-01,   8.58069083e-01,\n",
       "          8.55643237e-01,   9.04791499e-01,   2.42733783e-01,\n",
       "          3.40796762e-01,   1.19796191e-01,   7.57110834e-01,\n",
       "          3.62088941e-01],\n",
       "       [  8.84505855e-01,   5.00931361e-01,   5.72641033e-01,\n",
       "          9.73123490e-01,   9.89683795e-01,   9.31815951e-01,\n",
       "          3.08856166e-01,   3.82320266e-01,   4.88162975e-02,\n",
       "          8.64999708e-01,   2.18753407e-02,   2.71814059e-01,\n",
       "          9.90937120e-01,   9.69461498e-01,   7.04864125e-01,\n",
       "          8.46792904e-01,   2.22880160e-01,   2.61710363e-01,\n",
       "          4.51584441e-01,   1.25081044e-01,   5.60886086e-01,\n",
       "          9.46540545e-01,   7.10505144e-01,   1.34979953e-02,\n",
       "          6.94544311e-01,   4.84997131e-01,   7.59937757e-01,\n",
       "          8.40690341e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08200649  0.60281809  0.60957024  0.50482506  0.86048201  0.76671859\n",
      "   0.4987823   0.82740731  0.57641981  0.32262226  0.84695473  0.48043815\n",
      "   0.53257602  0.92100921  0.58847885  0.1095169   0.7527334   0.53630375\n",
      "   0.67068655  0.54831719  0.23068597  0.22722243  0.70044057  0.3642506\n",
      "   0.82246315  0.20856567  0.60973664  0.56457191  0.42264584  0.34516558\n",
      "   0.03628955  0.14923779  0.60392934  0.93156192  0.68356851  0.3946918\n",
      "   0.20367617  0.51275619  0.27974343  0.41472465  0.6428923   0.20051586\n",
      "   0.1829886   0.51024102  0.37143785  0.67592319  0.85170955  0.12859554\n",
      "   0.21229038  0.72046335  0.49640553  0.29414986  0.0878488   0.90716957\n",
      "   0.88924189  0.29649341  0.85424094  0.56274566  0.57399482  0.15858513\n",
      "   0.4051926   0.77726386  0.33251176  0.21524041  0.79867807  0.04889734\n",
      "   0.85020508  0.99185659  0.04059558  0.52476432  0.95583689  0.55915492\n",
      "   0.30432084  0.80281842  0.59083081]\n",
      " [ 0.60281809  0.60957024  0.50482506  0.86048201  0.42263087  0.4987823\n",
      "   0.82740731  0.57641981  0.32262226  0.85750526  0.48043815  0.53257602\n",
      "   0.92100921  0.58847885  0.83444061  0.7527334   0.53630375  0.67068655\n",
      "   0.54831719  0.01604199  0.22722243  0.70044057  0.3642506   0.82246315\n",
      "   0.8775268   0.60973664  0.56457191  0.42264584  0.34516558  0.27916012\n",
      "   0.14923779  0.60392934  0.93156192  0.68356851  0.05440425  0.20367617\n",
      "   0.51275619  0.27974343  0.41472465  0.85776086  0.20051586  0.1829886\n",
      "   0.51024102  0.37143785  0.97109509  0.85170955  0.12859554  0.21229038\n",
      "   0.72046335  0.93645476  0.29414986  0.0878488   0.90716957  0.88924189\n",
      "   0.94458091  0.85424094  0.56274566  0.57399482  0.15858513  0.91143957\n",
      "   0.77726386  0.33251176  0.21524041  0.79867807  0.18788491  0.85020508\n",
      "   0.99185659  0.04059558  0.52476432  0.63962458  0.55915492  0.30432084\n",
      "   0.80281842  0.59083081  0.12013266]\n",
      " [ 0.60957024  0.50482506  0.86048201  0.42263087  0.70999138  0.82740731\n",
      "   0.57641981  0.32262226  0.85750526  0.25960927  0.53257602  0.92100921\n",
      "   0.58847885  0.83444061  0.80558628  0.53630375  0.67068655  0.54831719\n",
      "   0.01604199  0.12521941  0.70044057  0.3642506   0.82246315  0.8775268\n",
      "   0.04097445  0.56457191  0.42264584  0.34516558  0.27916012  0.89770324\n",
      "   0.60392934  0.93156192  0.68356851  0.05440425  0.16919181  0.51275619\n",
      "   0.27974343  0.41472465  0.85776086  0.53149307  0.1829886   0.51024102\n",
      "   0.37143785  0.97109509  0.47309598  0.12859554  0.21229038  0.72046335\n",
      "   0.93645476  0.06018684  0.0878488   0.90716957  0.88924189  0.94458091\n",
      "   0.0059704   0.56274566  0.57399482  0.15858513  0.91143957  0.28837195\n",
      "   0.33251176  0.21524041  0.79867807  0.18788491  0.40065994  0.99185659\n",
      "   0.04059558  0.52476432  0.63962458  0.89156716  0.30432084  0.80281842\n",
      "   0.59083081  0.12013266  0.22751973]\n",
      " [ 0.76671859  0.4987823   0.82740731  0.57641981  0.32262226  0.84695473\n",
      "   0.48043815  0.53257602  0.92100921  0.58847885  0.1095169   0.7527334\n",
      "   0.53630375  0.67068655  0.54831719  0.23068597  0.22722243  0.70044057\n",
      "   0.3642506   0.82246315  0.8156736   0.332247    0.42636223  0.08764071\n",
      "   0.55248427  0.03628955  0.14923779  0.60392934  0.93156192  0.68356851\n",
      "   0.3946918   0.20367617  0.51275619  0.27974343  0.41472465  0.6428923\n",
      "   0.20051586  0.1829886   0.51024102  0.37143785  0.67592319  0.85170955\n",
      "   0.12859554  0.21229038  0.72046335  0.44987399  0.41257082  0.31227009\n",
      "   0.01161262  0.76016979  0.29649341  0.85424094  0.56274566  0.57399482\n",
      "   0.15858513  0.4051926   0.77726386  0.33251176  0.21524041  0.79867807\n",
      "   0.04889734  0.85020508  0.99185659  0.04059558  0.52476432  0.95583689\n",
      "   0.55915492  0.30432084  0.80281842  0.59083081  0.67830081  0.43670786\n",
      "   0.48111547  0.59891852  0.47656666]\n",
      " [ 0.4987823   0.82740731  0.57641981  0.32262226  0.85750526  0.48043815\n",
      "   0.53257602  0.92100921  0.58847885  0.83444061  0.7527334   0.53630375\n",
      "   0.67068655  0.54831719  0.01604199  0.22722243  0.70044057  0.3642506\n",
      "   0.82246315  0.8775268   0.332247    0.42636223  0.08764071  0.55248427\n",
      "   0.11751141  0.14923779  0.60392934  0.93156192  0.68356851  0.05440425\n",
      "   0.20367617  0.51275619  0.27974343  0.41472465  0.85776086  0.20051586\n",
      "   0.1829886   0.51024102  0.37143785  0.97109509  0.85170955  0.12859554\n",
      "   0.21229038  0.72046335  0.93645476  0.41257082  0.31227009  0.01161262\n",
      "   0.76016979  0.95639039  0.85424094  0.56274566  0.57399482  0.15858513\n",
      "   0.91143957  0.77726386  0.33251176  0.21524041  0.79867807  0.18788491\n",
      "   0.85020508  0.99185659  0.04059558  0.52476432  0.63962458  0.55915492\n",
      "   0.30432084  0.80281842  0.59083081  0.12013266  0.43670786  0.48111547\n",
      "   0.59891852  0.47656666  0.06863625]\n",
      " [ 0.82740731  0.57641981  0.32262226  0.85750526  0.25960927  0.53257602\n",
      "   0.92100921  0.58847885  0.83444061  0.80558628  0.53630375  0.67068655\n",
      "   0.54831719  0.01604199  0.12521941  0.70044057  0.3642506   0.82246315\n",
      "   0.8775268   0.04097445  0.42636223  0.08764071  0.55248427  0.11751141\n",
      "   0.52725023  0.60392934  0.93156192  0.68356851  0.05440425  0.16919181\n",
      "   0.51275619  0.27974343  0.41472465  0.85776086  0.53149307  0.1829886\n",
      "   0.51024102  0.37143785  0.97109509  0.47309598  0.12859554  0.21229038\n",
      "   0.72046335  0.93645476  0.06018684  0.31227009  0.01161262  0.76016979\n",
      "   0.95639039  0.35257778  0.56274566  0.57399482  0.15858513  0.91143957\n",
      "   0.28837195  0.33251176  0.21524041  0.79867807  0.18788491  0.40065994\n",
      "   0.99185659  0.04059558  0.52476432  0.63962458  0.89156716  0.30432084\n",
      "   0.80281842  0.59083081  0.12013266  0.22751973  0.48111547  0.59891852\n",
      "   0.47656666  0.06863625  0.82796701]\n",
      " [ 0.84695473  0.48043815  0.53257602  0.92100921  0.58847885  0.1095169\n",
      "   0.7527334   0.53630375  0.67068655  0.54831719  0.23068597  0.22722243\n",
      "   0.70044057  0.3642506   0.82246315  0.8156736   0.332247    0.42636223\n",
      "   0.08764071  0.55248427  0.73048361  0.9205018   0.38514251  0.0369571\n",
      "   0.46036969  0.3946918   0.20367617  0.51275619  0.27974343  0.41472465\n",
      "   0.6428923   0.20051586  0.1829886   0.51024102  0.37143785  0.67592319\n",
      "   0.85170955  0.12859554  0.21229038  0.72046335  0.44987399  0.41257082\n",
      "   0.31227009  0.01161262  0.76016979  0.90279544  0.86469388  0.67875842\n",
      "   0.26701169  0.96437793  0.4051926   0.77726386  0.33251176  0.21524041\n",
      "   0.79867807  0.04889734  0.85020508  0.99185659  0.04059558  0.52476432\n",
      "   0.95583689  0.55915492  0.30432084  0.80281842  0.59083081  0.67830081\n",
      "   0.43670786  0.48111547  0.59891852  0.47656666  0.23278249  0.81463747\n",
      "   0.65029974  0.61208276  0.14213349]\n",
      " [ 0.48043815  0.53257602  0.92100921  0.58847885  0.83444061  0.7527334\n",
      "   0.53630375  0.67068655  0.54831719  0.01604199  0.22722243  0.70044057\n",
      "   0.3642506   0.82246315  0.8775268   0.332247    0.42636223  0.08764071\n",
      "   0.55248427  0.11751141  0.9205018   0.38514251  0.0369571   0.46036969\n",
      "   0.40793194  0.20367617  0.51275619  0.27974343  0.41472465  0.85776086\n",
      "   0.20051586  0.1829886   0.51024102  0.37143785  0.97109509  0.85170955\n",
      "   0.12859554  0.21229038  0.72046335  0.93645476  0.41257082  0.31227009\n",
      "   0.01161262  0.76016979  0.95639039  0.86469388  0.67875842  0.26701169\n",
      "   0.96437793  0.74622123  0.77726386  0.33251176  0.21524041  0.79867807\n",
      "   0.18788491  0.85020508  0.99185659  0.04059558  0.52476432  0.63962458\n",
      "   0.55915492  0.30432084  0.80281842  0.59083081  0.12013266  0.43670786\n",
      "   0.48111547  0.59891852  0.47656666  0.06863625  0.81463747  0.65029974\n",
      "   0.61208276  0.14213349  0.95770859]\n",
      " [ 0.53257602  0.92100921  0.58847885  0.83444061  0.80558628  0.53630375\n",
      "   0.67068655  0.54831719  0.01604199  0.12521941  0.70044057  0.3642506\n",
      "   0.82246315  0.8775268   0.04097445  0.42636223  0.08764071  0.55248427\n",
      "   0.11751141  0.52725023  0.38514251  0.0369571   0.46036969  0.40793194\n",
      "   0.30346001  0.51275619  0.27974343  0.41472465  0.85776086  0.53149307\n",
      "   0.1829886   0.51024102  0.37143785  0.97109509  0.47309598  0.12859554\n",
      "   0.21229038  0.72046335  0.93645476  0.06018684  0.31227009  0.01161262\n",
      "   0.76016979  0.95639039  0.35257778  0.67875842  0.26701169  0.96437793\n",
      "   0.74622123  0.65092114  0.33251176  0.21524041  0.79867807  0.18788491\n",
      "   0.40065994  0.99185659  0.04059558  0.52476432  0.63962458  0.89156716\n",
      "   0.30432084  0.80281842  0.59083081  0.12013266  0.22751973  0.48111547\n",
      "   0.59891852  0.47656666  0.06863625  0.82796701  0.65029974  0.61208276\n",
      "   0.14213349  0.95770859  0.98070071]]\n",
      "(9, 75)\n",
      "[[ 0.83716418  0.40942364  0.91732132 ...,  0.96851301  0.52348467\n",
      "   0.79952165]\n",
      " [ 0.40942364  0.91732132  0.14969395 ...,  0.52348467  0.79952165\n",
      "   0.00317714]\n",
      " [ 0.91732132  0.14969395  0.69794269 ...,  0.79952165  0.00317714\n",
      "   0.68915537]\n",
      " ..., \n",
      " [ 0.66367261  0.80927183  0.7171366  ...,  0.99183688  0.05057292\n",
      "   0.33872992]\n",
      " [ 0.80927183  0.7171366   0.94769494 ...,  0.05057292  0.33872992\n",
      "   0.29881913]\n",
      " [ 0.7171366   0.94769494  0.88364474 ...,  0.33872992  0.29881913\n",
      "   0.92422965]]\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "import numpy as np\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1)\n",
    "print(col1.shape) # (9, 75)\n",
    "x2 = np.random.rand(10, 3, 7, 7) # 10 個のデータ \n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0) \n",
    "print(col2)\n",
    "print(col2.shape) # (90, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride = 1, pad = 0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2 * self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2 * self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        return out\n",
    "\n",
    "    \n",
    "# Poolingレイヤのbackward処理はReLUレイヤの実装で使ったmaxの逆伝播(5.5.1)が参考になるらしい\n",
    "# 実装はcommon/layer.pyにある\n",
    "\n",
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self/stride)\n",
    "        \n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "        out = np.max(col, axis = 1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3,1,2)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim = (1,28,28),\n",
    "                 conv_param = {'filter_num': 30, 'filter_size': 5,\n",
    "                              'pad':0, 'stride':1},\n",
    "                 hidden_size = 100, output_size =10, weight_init_std=0.01\n",
    "                ):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['filter_pad']\n",
    "        filter_stride = conv_param['fiter_stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2 * filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size / 2) * (conv_output_size / 2))\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "        return grads\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.29995003306\n",
      "=== epoch:1, train acc:0.286, test acc:0.278 ===\n",
      "train loss:2.29906235163\n",
      "train loss:2.29426167373\n",
      "train loss:2.28952462177\n",
      "train loss:2.28309055267\n",
      "train loss:2.27281134902\n",
      "train loss:2.27114245764\n",
      "train loss:2.24699509357\n",
      "train loss:2.24227652638\n",
      "train loss:2.21983742922\n",
      "train loss:2.1835868888\n",
      "train loss:2.14371549693\n",
      "train loss:2.11638414965\n",
      "train loss:2.05407661001\n",
      "train loss:2.0389507229\n",
      "train loss:2.02829945076\n",
      "train loss:1.9411216265\n",
      "train loss:1.83065424194\n",
      "train loss:1.75304960505\n",
      "train loss:1.7177022906\n",
      "train loss:1.66308472443\n",
      "train loss:1.51349695084\n",
      "train loss:1.46855829259\n",
      "train loss:1.45046279037\n",
      "train loss:1.38145277293\n",
      "train loss:1.24682437399\n",
      "train loss:1.22991111143\n",
      "train loss:1.00082384635\n",
      "train loss:1.03375610652\n",
      "train loss:1.03040354216\n",
      "train loss:0.949880491664\n",
      "train loss:1.00788266528\n",
      "train loss:0.857092846452\n",
      "train loss:0.867244712783\n",
      "train loss:0.735053795436\n",
      "train loss:0.838987999717\n",
      "train loss:0.738569355041\n",
      "train loss:0.720335329873\n",
      "train loss:0.66268507148\n",
      "train loss:0.715111421066\n",
      "train loss:0.604880778579\n",
      "train loss:0.596615983112\n",
      "train loss:0.645193936428\n",
      "train loss:0.518908347448\n",
      "train loss:0.877759664559\n",
      "train loss:0.486565623201\n",
      "train loss:0.427503842559\n",
      "train loss:0.513626365033\n",
      "train loss:0.432218585877\n",
      "train loss:0.41981435506\n",
      "train loss:0.71458611668\n",
      "=== epoch:2, train acc:0.822, test acc:0.797 ===\n",
      "train loss:0.439794023554\n",
      "train loss:0.454277696715\n",
      "train loss:0.431493595901\n",
      "train loss:0.438017066699\n",
      "train loss:0.512210136139\n",
      "train loss:0.49009005731\n",
      "train loss:0.567713033895\n",
      "train loss:0.587551255097\n",
      "train loss:0.535924360622\n",
      "train loss:0.42909816066\n",
      "train loss:0.51926705373\n",
      "train loss:0.504799144722\n",
      "train loss:0.403888566089\n",
      "train loss:0.414726138313\n",
      "train loss:0.490838228541\n",
      "train loss:0.422172153694\n",
      "train loss:0.443829488626\n",
      "train loss:0.347107956515\n",
      "train loss:0.27336511235\n",
      "train loss:0.284886849966\n",
      "train loss:0.423637860226\n",
      "train loss:0.536748577824\n",
      "train loss:0.473368527185\n",
      "train loss:0.315715204282\n",
      "train loss:0.325203074878\n",
      "train loss:0.284304750857\n",
      "train loss:0.46255030499\n",
      "train loss:0.367874960212\n",
      "train loss:0.483683855501\n",
      "train loss:0.489346331217\n",
      "train loss:0.33763099952\n",
      "train loss:0.345641709997\n",
      "train loss:0.353562587436\n",
      "train loss:0.551284804479\n",
      "train loss:0.313761402038\n",
      "train loss:0.36422124691\n",
      "train loss:0.424483647698\n",
      "train loss:0.336709333876\n",
      "train loss:0.319662115912\n",
      "train loss:0.400153678048\n",
      "train loss:0.328233268676\n",
      "train loss:0.337320996315\n",
      "train loss:0.381817894142\n",
      "train loss:0.308926999014\n",
      "train loss:0.268714583244\n",
      "train loss:0.396633336783\n",
      "train loss:0.316098988271\n",
      "train loss:0.333645635244\n",
      "train loss:0.223928123735\n",
      "train loss:0.326510977236\n",
      "=== epoch:3, train acc:0.874, test acc:0.861 ===\n",
      "train loss:0.285282729658\n",
      "train loss:0.288880053848\n",
      "train loss:0.295749065533\n",
      "train loss:0.33812041825\n",
      "train loss:0.414333187682\n",
      "train loss:0.483794838288\n",
      "train loss:0.357043946374\n",
      "train loss:0.377503224852\n",
      "train loss:0.331462793646\n",
      "train loss:0.210574415254\n",
      "train loss:0.331990218077\n",
      "train loss:0.418891148325\n",
      "train loss:0.248252802407\n",
      "train loss:0.404638994637\n",
      "train loss:0.269996119754\n",
      "train loss:0.54259742831\n",
      "train loss:0.384067116336\n",
      "train loss:0.347537745783\n",
      "train loss:0.219242505406\n",
      "train loss:0.258055260889\n",
      "train loss:0.279962683107\n",
      "train loss:0.374021328426\n",
      "train loss:0.275196977079\n",
      "train loss:0.274539675628\n",
      "train loss:0.216141462277\n",
      "train loss:0.393125041762\n",
      "train loss:0.240794791114\n",
      "train loss:0.236198146799\n",
      "train loss:0.406248960967\n",
      "train loss:0.171043736643\n",
      "train loss:0.446033020072\n",
      "train loss:0.147747413605\n",
      "train loss:0.531168904447\n",
      "train loss:0.252125787758\n",
      "train loss:0.241408396505\n",
      "train loss:0.234425500165\n",
      "train loss:0.279616928592\n",
      "train loss:0.372062108506\n",
      "train loss:0.273045430114\n",
      "train loss:0.203697555596\n",
      "train loss:0.285722382728\n",
      "train loss:0.302619194188\n",
      "train loss:0.140610057502\n",
      "train loss:0.252392754101\n",
      "train loss:0.27872820666\n",
      "train loss:0.383244422499\n",
      "train loss:0.232995009175\n",
      "train loss:0.228429958628\n",
      "train loss:0.152281664244\n",
      "train loss:0.303112566213\n",
      "=== epoch:4, train acc:0.901, test acc:0.888 ===\n",
      "train loss:0.183990902003\n",
      "train loss:0.453606848776\n",
      "train loss:0.238967010653\n",
      "train loss:0.478402219201\n",
      "train loss:0.159858256163\n",
      "train loss:0.174358161614\n",
      "train loss:0.220942953659\n",
      "train loss:0.284741150058\n",
      "train loss:0.267550441083\n",
      "train loss:0.290868581231\n",
      "train loss:0.17866411107\n",
      "train loss:0.222658299038\n",
      "train loss:0.269895918113\n",
      "train loss:0.194535104362\n",
      "train loss:0.354573996954\n",
      "train loss:0.193432702059\n",
      "train loss:0.341205672621\n",
      "train loss:0.173721832851\n",
      "train loss:0.179056658803\n",
      "train loss:0.165107641489\n",
      "train loss:0.253917779996\n",
      "train loss:0.33098484057\n",
      "train loss:0.224392591721\n",
      "train loss:0.391344336041\n",
      "train loss:0.138760759135\n",
      "train loss:0.278451731819\n",
      "train loss:0.26728331921\n",
      "train loss:0.163523737415\n",
      "train loss:0.270412091696\n",
      "train loss:0.234869976103\n",
      "train loss:0.241447884124\n",
      "train loss:0.245327768353\n",
      "train loss:0.293396844645\n",
      "train loss:0.307017723711\n",
      "train loss:0.221126153156\n",
      "train loss:0.233695576741\n",
      "train loss:0.145715998223\n",
      "train loss:0.290258443194\n",
      "train loss:0.227263321234\n",
      "train loss:0.141980731081\n",
      "train loss:0.228894396986\n",
      "train loss:0.227930543433\n",
      "train loss:0.122208483889\n",
      "train loss:0.306868648016\n",
      "train loss:0.105845269798\n",
      "train loss:0.240403267644\n",
      "train loss:0.209143127815\n",
      "train loss:0.293676539446\n",
      "train loss:0.239990797628\n",
      "train loss:0.401408773725\n",
      "=== epoch:5, train acc:0.927, test acc:0.914 ===\n",
      "train loss:0.198253359509\n",
      "train loss:0.16130228584\n",
      "train loss:0.120665213837\n",
      "train loss:0.178094109343\n",
      "train loss:0.237129634191\n",
      "train loss:0.214491602461\n",
      "train loss:0.0986985921272\n",
      "train loss:0.285924079975\n",
      "train loss:0.229616256445\n",
      "train loss:0.27182107595\n",
      "train loss:0.169627443079\n",
      "train loss:0.267820789862\n",
      "train loss:0.299282067201\n",
      "train loss:0.285753205705\n",
      "train loss:0.299724284114\n",
      "train loss:0.146488418412\n",
      "train loss:0.187380855962\n",
      "train loss:0.201052716982\n",
      "train loss:0.187690953735\n",
      "train loss:0.153368369898\n",
      "train loss:0.195336883954\n",
      "train loss:0.164940860896\n",
      "train loss:0.184577813777\n",
      "train loss:0.160408666503\n",
      "train loss:0.208791709016\n",
      "train loss:0.16770615729\n",
      "train loss:0.252415496544\n",
      "train loss:0.400086996672\n",
      "train loss:0.12931453113\n",
      "train loss:0.253977349312\n",
      "train loss:0.129462813511\n",
      "train loss:0.236193554955\n",
      "train loss:0.137743498498\n",
      "train loss:0.148022132641\n",
      "train loss:0.142598093407\n",
      "train loss:0.215615162077\n",
      "train loss:0.140638246456\n",
      "train loss:0.183386816268\n",
      "train loss:0.26927046402\n",
      "train loss:0.260484970495\n",
      "train loss:0.158991238162\n",
      "train loss:0.101976032285\n",
      "train loss:0.281340094157\n",
      "train loss:0.334625519802\n",
      "train loss:0.208100381693\n",
      "train loss:0.253579559865\n",
      "train loss:0.208553086593\n",
      "train loss:0.0728524133592\n",
      "train loss:0.159002342876\n",
      "train loss:0.137364458889\n",
      "=== epoch:6, train acc:0.932, test acc:0.911 ===\n",
      "train loss:0.164816069117\n",
      "train loss:0.208524711338\n",
      "train loss:0.213103936169\n",
      "train loss:0.184045485659\n",
      "train loss:0.273262620093\n",
      "train loss:0.191441071082\n",
      "train loss:0.148064377382\n",
      "train loss:0.154337823824\n",
      "train loss:0.151617841215\n",
      "train loss:0.193462036735\n",
      "train loss:0.263731571531\n",
      "train loss:0.162780500442\n",
      "train loss:0.193814155195\n",
      "train loss:0.218434171403\n",
      "train loss:0.111158320519\n",
      "train loss:0.300522638981\n",
      "train loss:0.233738137122\n",
      "train loss:0.100150718063\n",
      "train loss:0.139736299221\n",
      "train loss:0.177899383163\n",
      "train loss:0.18544300572\n",
      "train loss:0.139193654346\n",
      "train loss:0.160486774785\n",
      "train loss:0.200557780749\n",
      "train loss:0.169647229154\n",
      "train loss:0.195856099767\n",
      "train loss:0.144046339684\n",
      "train loss:0.22243233272\n",
      "train loss:0.20056659371\n",
      "train loss:0.239347103877\n",
      "train loss:0.221919856673\n",
      "train loss:0.166227171835\n",
      "train loss:0.229592806515\n",
      "train loss:0.141450753665\n",
      "train loss:0.260962085661\n",
      "train loss:0.11989395771\n",
      "train loss:0.128979884994\n",
      "train loss:0.18279974997\n",
      "train loss:0.102943467044\n",
      "train loss:0.121944223895\n",
      "train loss:0.143970953156\n",
      "train loss:0.102006873405\n",
      "train loss:0.134904309065\n",
      "train loss:0.126343663684\n",
      "train loss:0.142466169867\n",
      "train loss:0.134726137019\n",
      "train loss:0.176790210992\n",
      "train loss:0.195183019243\n",
      "train loss:0.226424971704\n",
      "train loss:0.178511918573\n",
      "=== epoch:7, train acc:0.944, test acc:0.924 ===\n",
      "train loss:0.258225100259\n",
      "train loss:0.129613102056\n",
      "train loss:0.243414614557\n",
      "train loss:0.254575036013\n",
      "train loss:0.125317698422\n",
      "train loss:0.158937894041\n",
      "train loss:0.0781780588813\n",
      "train loss:0.154920704724\n",
      "train loss:0.0458069056632\n",
      "train loss:0.125414111384\n",
      "train loss:0.171471477039\n",
      "train loss:0.147222614252\n",
      "train loss:0.113453534223\n",
      "train loss:0.219345012248\n",
      "train loss:0.140176306747\n",
      "train loss:0.114716707433\n",
      "train loss:0.170501575828\n",
      "train loss:0.202650003605\n",
      "train loss:0.13599072564\n",
      "train loss:0.157363770622\n",
      "train loss:0.07615840785\n",
      "train loss:0.115149239944\n",
      "train loss:0.0810638815\n",
      "train loss:0.147195016815\n",
      "train loss:0.0931115429712\n",
      "train loss:0.165472026656\n",
      "train loss:0.100303202111\n",
      "train loss:0.148148474036\n",
      "train loss:0.16305353955\n",
      "train loss:0.146181037139\n",
      "train loss:0.0500531378866\n",
      "train loss:0.167330136711\n",
      "train loss:0.148492696293\n",
      "train loss:0.107781554029\n",
      "train loss:0.158556771172\n",
      "train loss:0.105046891158\n",
      "train loss:0.0667253363904\n",
      "train loss:0.177920396233\n",
      "train loss:0.155076452265\n",
      "train loss:0.158545038583\n",
      "train loss:0.110953272529\n",
      "train loss:0.232072514693\n",
      "train loss:0.169621707215\n",
      "train loss:0.0692150504712\n",
      "train loss:0.139133716977\n",
      "train loss:0.11653754171\n",
      "train loss:0.0839641134145\n",
      "train loss:0.10919379186\n",
      "train loss:0.10368509238\n",
      "train loss:0.122030597692\n",
      "=== epoch:8, train acc:0.955, test acc:0.928 ===\n",
      "train loss:0.0570175798443\n",
      "train loss:0.0649852135416\n",
      "train loss:0.101052985636\n",
      "train loss:0.133660651251\n",
      "train loss:0.0419016395106\n",
      "train loss:0.212717668303\n",
      "train loss:0.108058360274\n",
      "train loss:0.0958557381518\n",
      "train loss:0.188247840725\n",
      "train loss:0.113681035002\n",
      "train loss:0.147215100581\n",
      "train loss:0.229155418301\n",
      "train loss:0.0926450245739\n",
      "train loss:0.161060427106\n",
      "train loss:0.112199611917\n",
      "train loss:0.0896979935148\n",
      "train loss:0.0754791204994\n",
      "train loss:0.0667523295174\n",
      "train loss:0.0674354350514\n",
      "train loss:0.12843681088\n",
      "train loss:0.125434828323\n",
      "train loss:0.16910435371\n",
      "train loss:0.0634947802042\n",
      "train loss:0.0880134099904\n",
      "train loss:0.10549471353\n",
      "train loss:0.0699218100655\n",
      "train loss:0.136481291359\n",
      "train loss:0.0634163476812\n",
      "train loss:0.0828087544412\n",
      "train loss:0.0978990904196\n",
      "train loss:0.115059123085\n",
      "train loss:0.14407322195\n",
      "train loss:0.120779098267\n",
      "train loss:0.0829559396237\n",
      "train loss:0.0514969674764\n",
      "train loss:0.098304932646\n",
      "train loss:0.12599343814\n",
      "train loss:0.0687397648375\n",
      "train loss:0.163658452351\n",
      "train loss:0.1799114326\n",
      "train loss:0.0662094497111\n",
      "train loss:0.100005118343\n",
      "train loss:0.153482487503\n",
      "train loss:0.139449299093\n",
      "train loss:0.10178172893\n",
      "train loss:0.1755524189\n",
      "train loss:0.103416577738\n",
      "train loss:0.185083484732\n",
      "train loss:0.0671493928028\n",
      "train loss:0.0972534581615\n",
      "=== epoch:9, train acc:0.955, test acc:0.934 ===\n",
      "train loss:0.0496232469025\n",
      "train loss:0.0647133688987\n",
      "train loss:0.146911880921\n",
      "train loss:0.142950465171\n",
      "train loss:0.120277534786\n",
      "train loss:0.129185610677\n",
      "train loss:0.0716728628308\n",
      "train loss:0.148981227976\n",
      "train loss:0.0641369682351\n",
      "train loss:0.147312349117\n",
      "train loss:0.0560827259264\n",
      "train loss:0.17920135894\n",
      "train loss:0.0781489944749\n",
      "train loss:0.158750554626\n",
      "train loss:0.122418948281\n",
      "train loss:0.209503139265\n",
      "train loss:0.102050820341\n",
      "train loss:0.0526637964412\n",
      "train loss:0.123012619749\n",
      "train loss:0.147450443453\n",
      "train loss:0.0939501701076\n",
      "train loss:0.10508254192\n",
      "train loss:0.068830400428\n",
      "train loss:0.0877446926388\n",
      "train loss:0.0896977520717\n",
      "train loss:0.114072604345\n",
      "train loss:0.0935055499071\n",
      "train loss:0.10951647343\n",
      "train loss:0.153173468476\n",
      "train loss:0.0969616632487\n",
      "train loss:0.0721466880271\n",
      "train loss:0.179463219581\n",
      "train loss:0.080221050585\n",
      "train loss:0.160712672958\n",
      "train loss:0.0927000649743\n",
      "train loss:0.141305667685\n",
      "train loss:0.0522086147488\n",
      "train loss:0.112337221178\n",
      "train loss:0.112271974256\n",
      "train loss:0.120596905211\n",
      "train loss:0.111696306453\n",
      "train loss:0.106046276469\n",
      "train loss:0.111447087451\n",
      "train loss:0.115510722951\n",
      "train loss:0.0806739615849\n",
      "train loss:0.179265365655\n",
      "train loss:0.0980059421605\n",
      "train loss:0.125022324374\n",
      "train loss:0.141084584635\n",
      "train loss:0.0706045066513\n",
      "=== epoch:10, train acc:0.965, test acc:0.943 ===\n",
      "train loss:0.0613798966462\n",
      "train loss:0.108027925902\n",
      "train loss:0.0419768115024\n",
      "train loss:0.10389680068\n",
      "train loss:0.122564955564\n",
      "train loss:0.168672020369\n",
      "train loss:0.0921001538276\n",
      "train loss:0.0803968452083\n",
      "train loss:0.0971440995181\n",
      "train loss:0.0860862586614\n",
      "train loss:0.159914504154\n",
      "train loss:0.131561260187\n",
      "train loss:0.0578467766914\n",
      "train loss:0.118064200466\n",
      "train loss:0.139830373791\n",
      "train loss:0.068980407247\n",
      "train loss:0.107976310263\n",
      "train loss:0.086397385556\n",
      "train loss:0.104086815615\n",
      "train loss:0.0738893531096\n",
      "train loss:0.0820868367027\n",
      "train loss:0.11846372487\n",
      "train loss:0.0368293506183\n",
      "train loss:0.063476369469\n",
      "train loss:0.149224238997\n",
      "train loss:0.12552170657\n",
      "train loss:0.108743253654\n",
      "train loss:0.136096738047\n",
      "train loss:0.159232825096\n",
      "train loss:0.0769604635432\n",
      "train loss:0.0839989722958\n",
      "train loss:0.0617770553452\n",
      "train loss:0.0549057707095\n",
      "train loss:0.0430448263479\n",
      "train loss:0.082832198861\n",
      "train loss:0.0291043421849\n",
      "train loss:0.0601198473518\n",
      "train loss:0.0947153774323\n",
      "train loss:0.0641148688688\n",
      "train loss:0.0730572663117\n",
      "train loss:0.15581653019\n",
      "train loss:0.0354019523004\n",
      "train loss:0.0798961598273\n",
      "train loss:0.0819035891544\n",
      "train loss:0.0596126823142\n",
      "train loss:0.0723520744537\n",
      "train loss:0.0919209865594\n",
      "train loss:0.0986225290877\n",
      "train loss:0.0423642780303\n",
      "train loss:0.0729579869268\n",
      "=== epoch:11, train acc:0.97, test acc:0.947 ===\n",
      "train loss:0.0344954983859\n",
      "train loss:0.0504530116559\n",
      "train loss:0.0990017355734\n",
      "train loss:0.0850717348159\n",
      "train loss:0.140463892949\n",
      "train loss:0.065081848883\n",
      "train loss:0.060363833708\n",
      "train loss:0.0637872898476\n",
      "train loss:0.135975167004\n",
      "train loss:0.0695454267738\n",
      "train loss:0.0752645873343\n",
      "train loss:0.0908512767984\n",
      "train loss:0.0979726586127\n",
      "train loss:0.155376202116\n",
      "train loss:0.0452184847303\n",
      "train loss:0.0156955958565\n",
      "train loss:0.0759088966974\n",
      "train loss:0.092682301453\n",
      "train loss:0.114492189981\n",
      "train loss:0.218104790297\n",
      "train loss:0.0909247938152\n",
      "train loss:0.0862827548318\n",
      "train loss:0.062572264819\n",
      "train loss:0.0928487728661\n",
      "train loss:0.0783781257177\n",
      "train loss:0.145744195386\n",
      "train loss:0.116991561859\n",
      "train loss:0.0415463972957\n",
      "train loss:0.0556203343052\n",
      "train loss:0.0330101383413\n",
      "train loss:0.0816399432131\n",
      "train loss:0.0620137377509\n",
      "train loss:0.151324615596\n",
      "train loss:0.0508978343564\n",
      "train loss:0.109084697632\n",
      "train loss:0.126442041755\n",
      "train loss:0.0946334577687\n",
      "train loss:0.0305172954836\n",
      "train loss:0.11881436751\n",
      "train loss:0.0427829064159\n",
      "train loss:0.0800812464843\n",
      "train loss:0.121490848476\n",
      "train loss:0.112603496115\n",
      "train loss:0.126249932788\n",
      "train loss:0.0486759149812\n",
      "train loss:0.132437286065\n",
      "train loss:0.0213050446439\n",
      "train loss:0.108032262236\n",
      "train loss:0.054754553967\n",
      "train loss:0.164118696198\n",
      "=== epoch:12, train acc:0.962, test acc:0.945 ===\n",
      "train loss:0.0471999924195\n",
      "train loss:0.0285212392904\n",
      "train loss:0.0592174490994\n",
      "train loss:0.0934633688968\n",
      "train loss:0.0682596654543\n",
      "train loss:0.0468659315303\n",
      "train loss:0.162261187542\n",
      "train loss:0.0641417405233\n",
      "train loss:0.0658856715515\n",
      "train loss:0.084158582576\n",
      "train loss:0.0297423741144\n",
      "train loss:0.100100598291\n",
      "train loss:0.116990104377\n",
      "train loss:0.176035341688\n",
      "train loss:0.0385652833437\n",
      "train loss:0.0676899612107\n",
      "train loss:0.0620660504294\n",
      "train loss:0.0657535176608\n",
      "train loss:0.0627621664212\n",
      "train loss:0.0747875294287\n",
      "train loss:0.0584492160459\n",
      "train loss:0.0383395110394\n",
      "train loss:0.0963482236531\n",
      "train loss:0.0611850030848\n",
      "train loss:0.104749355667\n",
      "train loss:0.033385023709\n",
      "train loss:0.0492308024224\n",
      "train loss:0.0475894060224\n",
      "train loss:0.0205944525756\n",
      "train loss:0.0669432664279\n",
      "train loss:0.0617101882078\n",
      "train loss:0.0555731175143\n",
      "train loss:0.0879991244392\n",
      "train loss:0.0548913461476\n",
      "train loss:0.0830106622956\n",
      "train loss:0.0281901323073\n",
      "train loss:0.0534536327936\n",
      "train loss:0.0899157887777\n",
      "train loss:0.063294839142\n",
      "train loss:0.0539352808993\n",
      "train loss:0.0633092429681\n",
      "train loss:0.0705324520147\n",
      "train loss:0.181255918479\n",
      "train loss:0.0490451560573\n",
      "train loss:0.0555229733984\n",
      "train loss:0.0606864698225\n",
      "train loss:0.113784075\n",
      "train loss:0.042663229651\n",
      "train loss:0.0234921978666\n",
      "train loss:0.101413953659\n",
      "=== epoch:13, train acc:0.979, test acc:0.951 ===\n",
      "train loss:0.0392645250819\n",
      "train loss:0.0379630236969\n",
      "train loss:0.0397707030955\n",
      "train loss:0.0600151069772\n",
      "train loss:0.0380091520858\n",
      "train loss:0.064848546378\n",
      "train loss:0.101365554963\n",
      "train loss:0.0660590204709\n",
      "train loss:0.0417926238181\n",
      "train loss:0.0291457048462\n",
      "train loss:0.02069816558\n",
      "train loss:0.105019135697\n",
      "train loss:0.0573341508\n",
      "train loss:0.0498494135973\n",
      "train loss:0.0430544224398\n",
      "train loss:0.0481063666077\n",
      "train loss:0.0608795780705\n",
      "train loss:0.0311750946744\n",
      "train loss:0.0336823203625\n",
      "train loss:0.0626800530513\n",
      "train loss:0.0354323488283\n",
      "train loss:0.023548043519\n",
      "train loss:0.121243396547\n",
      "train loss:0.0212753207055\n",
      "train loss:0.0781528978679\n",
      "train loss:0.0324323439752\n",
      "train loss:0.0426147387818\n",
      "train loss:0.0347349927155\n",
      "train loss:0.0410600685332\n",
      "train loss:0.0597347746416\n",
      "train loss:0.0560343177034\n",
      "train loss:0.0370477091758\n",
      "train loss:0.0849897996764\n",
      "train loss:0.042510301016\n",
      "train loss:0.0453351114267\n",
      "train loss:0.0266546664483\n",
      "train loss:0.0558443523266\n",
      "train loss:0.0221695743371\n",
      "train loss:0.0361315202358\n",
      "train loss:0.0507649627228\n",
      "train loss:0.0500623971398\n",
      "train loss:0.041767805887\n",
      "train loss:0.0610392872755\n",
      "train loss:0.0258038507526\n",
      "train loss:0.0152977452397\n",
      "train loss:0.056290017821\n",
      "train loss:0.079829977214\n",
      "train loss:0.0501386021978\n",
      "train loss:0.0899479405086\n",
      "train loss:0.0287144624487\n",
      "=== epoch:14, train acc:0.979, test acc:0.961 ===\n",
      "train loss:0.061329097758\n",
      "train loss:0.0235958112805\n",
      "train loss:0.0396233942424\n",
      "train loss:0.0566823541436\n",
      "train loss:0.0474832327319\n",
      "train loss:0.0701150379293\n",
      "train loss:0.0797940773624\n",
      "train loss:0.129411436774\n",
      "train loss:0.0677073871713\n",
      "train loss:0.014804990729\n",
      "train loss:0.0576405484857\n",
      "train loss:0.0520005335459\n",
      "train loss:0.0363611255289\n",
      "train loss:0.0670094525201\n",
      "train loss:0.0647775325618\n",
      "train loss:0.040862157828\n",
      "train loss:0.0307399420259\n",
      "train loss:0.0317520166894\n",
      "train loss:0.0220978913352\n",
      "train loss:0.0240793151535\n",
      "train loss:0.0520154782448\n",
      "train loss:0.0280515895651\n",
      "train loss:0.0456343761303\n",
      "train loss:0.0586979318712\n",
      "train loss:0.025944487536\n",
      "train loss:0.0422831970874\n",
      "train loss:0.0345743666054\n",
      "train loss:0.0476095701499\n",
      "train loss:0.113652435022\n",
      "train loss:0.0305871842676\n",
      "train loss:0.0304604004646\n",
      "train loss:0.0275114585952\n",
      "train loss:0.0651607800581\n",
      "train loss:0.0887029181485\n",
      "train loss:0.0730818062922\n",
      "train loss:0.0573970091125\n",
      "train loss:0.0316977516227\n",
      "train loss:0.0184218543019\n",
      "train loss:0.0433658619071\n",
      "train loss:0.0604460292147\n",
      "train loss:0.0813073265404\n",
      "train loss:0.0318290194779\n",
      "train loss:0.0497195652372\n",
      "train loss:0.1431866034\n",
      "train loss:0.0176403075833\n",
      "train loss:0.0412992117516\n",
      "train loss:0.0803434055802\n",
      "train loss:0.103185241197\n",
      "train loss:0.0411298281976\n",
      "train loss:0.0319555438002\n",
      "=== epoch:15, train acc:0.975, test acc:0.958 ===\n",
      "train loss:0.0515324557559\n",
      "train loss:0.0807096001365\n",
      "train loss:0.134199355551\n",
      "train loss:0.0996341398039\n",
      "train loss:0.0569476933042\n",
      "train loss:0.0514654175883\n",
      "train loss:0.0372130097433\n",
      "train loss:0.0204160560419\n",
      "train loss:0.0659914883822\n",
      "train loss:0.0717238584092\n",
      "train loss:0.0647118326717\n",
      "train loss:0.0941935526387\n",
      "train loss:0.0501569330839\n",
      "train loss:0.0319148539784\n",
      "train loss:0.0873772543958\n",
      "train loss:0.0393646653785\n",
      "train loss:0.0508132990913\n",
      "train loss:0.0457988834274\n",
      "train loss:0.0411945216166\n",
      "train loss:0.0392410849022\n",
      "train loss:0.017058572222\n",
      "train loss:0.046014140862\n",
      "train loss:0.0416090587642\n",
      "train loss:0.0678574446273\n",
      "train loss:0.0223345784602\n",
      "train loss:0.0342506953414\n",
      "train loss:0.0320737003567\n",
      "train loss:0.0210709893797\n",
      "train loss:0.0259039267585\n",
      "train loss:0.0580883321884\n",
      "train loss:0.0500864112265\n",
      "train loss:0.0278378190506\n",
      "train loss:0.105341631611\n",
      "train loss:0.0508934564571\n",
      "train loss:0.0463964669587\n",
      "train loss:0.0340877209729\n",
      "train loss:0.0442811646935\n",
      "train loss:0.030723253429\n",
      "train loss:0.0453283462071\n",
      "train loss:0.0556898592317\n",
      "train loss:0.0131648643699\n",
      "train loss:0.0366660586658\n",
      "train loss:0.1140014177\n",
      "train loss:0.0495499695151\n",
      "train loss:0.032951772975\n",
      "train loss:0.0465915402312\n",
      "train loss:0.0378824754767\n",
      "train loss:0.0277071733724\n",
      "train loss:0.0349844159694\n",
      "train loss:0.0265715740302\n",
      "=== epoch:16, train acc:0.978, test acc:0.963 ===\n",
      "train loss:0.021182766475\n",
      "train loss:0.015682037011\n",
      "train loss:0.0355435836045\n",
      "train loss:0.0479965064074\n",
      "train loss:0.0310754619561\n",
      "train loss:0.0250538676637\n",
      "train loss:0.037434867443\n",
      "train loss:0.0394757292091\n",
      "train loss:0.125150181202\n",
      "train loss:0.0439523812373\n",
      "train loss:0.0388767470063\n",
      "train loss:0.0308453168778\n",
      "train loss:0.0167063850967\n",
      "train loss:0.014107072865\n",
      "train loss:0.0274122706797\n",
      "train loss:0.0275232329534\n",
      "train loss:0.0310844731311\n",
      "train loss:0.0207294907704\n",
      "train loss:0.0259516329113\n",
      "train loss:0.0223122578646\n",
      "train loss:0.0640991096995\n",
      "train loss:0.0219101028732\n",
      "train loss:0.0262282655289\n",
      "train loss:0.109265079409\n",
      "train loss:0.0230419119313\n",
      "train loss:0.0595431563306\n",
      "train loss:0.0263254896487\n",
      "train loss:0.0783030041578\n",
      "train loss:0.018760937978\n",
      "train loss:0.0264873832321\n",
      "train loss:0.0335621117391\n",
      "train loss:0.0198326524238\n",
      "train loss:0.0358872441627\n",
      "train loss:0.0524336734369\n",
      "train loss:0.0374709979571\n",
      "train loss:0.0500869205421\n",
      "train loss:0.0313566406362\n",
      "train loss:0.0731364351683\n",
      "train loss:0.0182213034289\n",
      "train loss:0.020118184493\n",
      "train loss:0.0489635747247\n",
      "train loss:0.0410904491852\n",
      "train loss:0.0209814133422\n",
      "train loss:0.073750686876\n",
      "train loss:0.0441810647192\n",
      "train loss:0.0479365483381\n",
      "train loss:0.0650443182997\n",
      "train loss:0.0204674580181\n",
      "train loss:0.025886963295\n",
      "train loss:0.0195519810073\n",
      "=== epoch:17, train acc:0.982, test acc:0.96 ===\n",
      "train loss:0.03211192834\n",
      "train loss:0.038420393652\n",
      "train loss:0.0175834161376\n",
      "train loss:0.0164824064793\n",
      "train loss:0.036438398662\n",
      "train loss:0.0818995161461\n",
      "train loss:0.017143707286\n",
      "train loss:0.0392016916499\n",
      "train loss:0.0460784038939\n",
      "train loss:0.0149668662325\n",
      "train loss:0.0446678527471\n",
      "train loss:0.0265935193982\n",
      "train loss:0.043623275777\n",
      "train loss:0.0297576269455\n",
      "train loss:0.0589391834309\n",
      "train loss:0.0787018279158\n",
      "train loss:0.034359804345\n",
      "train loss:0.0100530302979\n",
      "train loss:0.052737109241\n",
      "train loss:0.00761483350316\n",
      "train loss:0.0363290635057\n",
      "train loss:0.0286804817201\n",
      "train loss:0.0296008512442\n",
      "train loss:0.0459164911443\n",
      "train loss:0.0372427427728\n",
      "train loss:0.0270171427376\n",
      "train loss:0.0154226017915\n",
      "train loss:0.0262347048795\n",
      "train loss:0.0168035032913\n",
      "train loss:0.0189786650011\n",
      "train loss:0.0469114244258\n",
      "train loss:0.0850705079988\n",
      "train loss:0.0634769768561\n",
      "train loss:0.0237309737887\n",
      "train loss:0.040295896522\n",
      "train loss:0.0277784270637\n",
      "train loss:0.0368977262792\n",
      "train loss:0.0438147698759\n",
      "train loss:0.0723470511355\n",
      "train loss:0.0595681330232\n",
      "train loss:0.0414811449895\n",
      "train loss:0.0306915043245\n",
      "train loss:0.0359999176952\n",
      "train loss:0.0831705105251\n",
      "train loss:0.0239755649954\n",
      "train loss:0.0450491501247\n",
      "train loss:0.0250025958214\n",
      "train loss:0.0271337278377\n",
      "train loss:0.0427287733663\n",
      "train loss:0.0412290284736\n",
      "=== epoch:18, train acc:0.986, test acc:0.955 ===\n",
      "train loss:0.0307252441129\n",
      "train loss:0.0165263793039\n",
      "train loss:0.0373189894416\n",
      "train loss:0.0618541095089\n",
      "train loss:0.0430332675224\n",
      "train loss:0.0283374957175\n",
      "train loss:0.0260195868041\n",
      "train loss:0.0179615716438\n",
      "train loss:0.0255212572279\n",
      "train loss:0.0136884795762\n",
      "train loss:0.011373765868\n",
      "train loss:0.0544529017963\n",
      "train loss:0.0380638833724\n",
      "train loss:0.0146396273082\n",
      "train loss:0.0295137865923\n",
      "train loss:0.0183804516944\n",
      "train loss:0.0266995576543\n",
      "train loss:0.0453254248616\n",
      "train loss:0.032288612006\n",
      "train loss:0.0126793767987\n",
      "train loss:0.0196474049483\n",
      "train loss:0.0203359850253\n",
      "train loss:0.0340146729027\n",
      "train loss:0.0565008552261\n",
      "train loss:0.0555994150178\n",
      "train loss:0.0481922659511\n",
      "train loss:0.0217426214559\n",
      "train loss:0.0794246588166\n",
      "train loss:0.0258185757201\n",
      "train loss:0.0434512246945\n",
      "train loss:0.0313957292066\n",
      "train loss:0.0188676948303\n",
      "train loss:0.0198491684227\n",
      "train loss:0.0276800522673\n",
      "train loss:0.0154245342807\n",
      "train loss:0.0598669713684\n",
      "train loss:0.0169903686398\n",
      "train loss:0.0175892450574\n",
      "train loss:0.0214047257044\n",
      "train loss:0.0401478982507\n",
      "train loss:0.0305949538934\n",
      "train loss:0.0390938564503\n",
      "train loss:0.0106244541194\n",
      "train loss:0.0474855458904\n",
      "train loss:0.0249832394742\n",
      "train loss:0.0222615382061\n",
      "train loss:0.0533236430396\n",
      "train loss:0.0353600913624\n",
      "train loss:0.033209437908\n",
      "train loss:0.0270487664602\n",
      "=== epoch:19, train acc:0.988, test acc:0.956 ===\n",
      "train loss:0.0222315893265\n",
      "train loss:0.035566944886\n",
      "train loss:0.0175221992549\n",
      "train loss:0.0661534804676\n",
      "train loss:0.0156953556832\n",
      "train loss:0.0115610878978\n",
      "train loss:0.0606695106134\n",
      "train loss:0.021220912675\n",
      "train loss:0.0165806632872\n",
      "train loss:0.00545501125797\n",
      "train loss:0.01490252535\n",
      "train loss:0.0431268939484\n",
      "train loss:0.0270002210836\n",
      "train loss:0.0411247028034\n",
      "train loss:0.0501412228563\n",
      "train loss:0.0194522914896\n",
      "train loss:0.0126523474557\n",
      "train loss:0.0177141556438\n",
      "train loss:0.0295513699843\n",
      "train loss:0.04192634209\n",
      "train loss:0.0118885293238\n",
      "train loss:0.0173648974638\n",
      "train loss:0.0284185013923\n",
      "train loss:0.0472261754858\n",
      "train loss:0.0236228111555\n",
      "train loss:0.0247654237665\n",
      "train loss:0.0101675941073\n",
      "train loss:0.0285345319539\n",
      "train loss:0.00912293625452\n",
      "train loss:0.0411963845981\n",
      "train loss:0.015595904441\n",
      "train loss:0.0207263402155\n",
      "train loss:0.0719280000206\n",
      "train loss:0.0189884125688\n",
      "train loss:0.0233947766004\n",
      "train loss:0.023328392487\n",
      "train loss:0.0104976179527\n",
      "train loss:0.0253203106078\n",
      "train loss:0.0177536623121\n",
      "train loss:0.0613520291814\n",
      "train loss:0.0245659933476\n",
      "train loss:0.0238240535959\n",
      "train loss:0.0174313013901\n",
      "train loss:0.0365506920583\n",
      "train loss:0.0144713947328\n",
      "train loss:0.0133258698065\n",
      "train loss:0.0307573814265\n",
      "train loss:0.0240178824772\n",
      "train loss:0.00719468452534\n",
      "train loss:0.0149530908332\n",
      "=== epoch:20, train acc:0.989, test acc:0.956 ===\n",
      "train loss:0.0206277491488\n",
      "train loss:0.0274106966249\n",
      "train loss:0.0136800054148\n",
      "train loss:0.0278851437177\n",
      "train loss:0.0145080145532\n",
      "train loss:0.0190252951864\n",
      "train loss:0.0179109051544\n",
      "train loss:0.0220384727186\n",
      "train loss:0.0128143464689\n",
      "train loss:0.0276779130014\n",
      "train loss:0.0114284831656\n",
      "train loss:0.0252703731308\n",
      "train loss:0.0156484338063\n",
      "train loss:0.0355833247229\n",
      "train loss:0.0256278838605\n",
      "train loss:0.0218018008372\n",
      "train loss:0.0270508511692\n",
      "train loss:0.0149625913081\n",
      "train loss:0.016834830983\n",
      "train loss:0.0221133632434\n",
      "train loss:0.0286467640154\n",
      "train loss:0.0199055790662\n",
      "train loss:0.0349325975447\n",
      "train loss:0.0243353996697\n",
      "train loss:0.00518296781152\n",
      "train loss:0.0450904110332\n",
      "train loss:0.0235153290923\n",
      "train loss:0.0171442594173\n",
      "train loss:0.0162124952754\n",
      "train loss:0.0107364243062\n",
      "train loss:0.0247414532085\n",
      "train loss:0.0109727145341\n",
      "train loss:0.0198586867299\n",
      "train loss:0.00884507091045\n",
      "train loss:0.0130013332588\n",
      "train loss:0.0110761804907\n",
      "train loss:0.0185905657901\n",
      "train loss:0.0210733409409\n",
      "train loss:0.0123349726819\n",
      "train loss:0.0162400428335\n",
      "train loss:0.015037221074\n",
      "train loss:0.0286231624883\n",
      "train loss:0.0101154639503\n",
      "train loss:0.0139112175792\n",
      "train loss:0.0253782725157\n",
      "train loss:0.0256672683777\n",
      "train loss:0.0412720246738\n",
      "train loss:0.0124560330525\n",
      "train loss:0.0124806824501\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.958\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAF5CAYAAADQ2iM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIRo+AhIiIiEaPgISIiIhHz/wO990gRaS8q1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110ce2ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from ch7.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGLCAYAAACY4NX7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrAEAAASMsgYAABAwyhoAAEDA/h/nUZt2793SNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111828080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGLCAYAAACY4NX7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1117df2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ch7.simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# ランダム初期化後の重み\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 学習後の重み\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
